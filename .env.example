# AI Configuration
AI_MODEL=gpt-4o                    # Examples: gpt-4o, gemini-2.0-flash, gemini-2.5-pro
# AI_PROVIDER=                     # Auto-detected from model name. Override: local, openai, gemini, cloud, webllm
# AI_ENDPOINT=                     # Auto-detected from provider. Override with custom URL if needed
AI_TEMPERATURE=0.7
AI_MAX_TOKENS=4096
AI_CONTEXT_WINDOW=128000
AI_MAX_TURNS=100                     # Maximum conversation turns per agent execution (increase for complex tasks)
AI_PROVIDER=gemini

# Model Routing Configuration
# Map task roles to specific models. If unset, defaults to AI_MODEL.
# ROUTE_AGENTIC=gemini-2.5-flash
# ROUTE_REASONING_HIGH=gemini-2.5-pro
# ROUTE_REASONING_MEDIUM=gemini-2.5-flash
# ROUTE_REASONING_LOW=gemini-2.0-flash
# ROUTE_SUMMARIZER=gemini-2.0-flash
# ROUTE_CODE_COMPLETION=gemini-2.0-flash

# Google Vertex AI Configuration (for Anthropic/Claude models)
# Authentication is handled via Google Cloud ADC (gcloud auth application-default login)
# VERTEX_PROJECT_ID=your-gcp-project-id
# VERTEX_REGION=us-east5

# System Configuration
NODE_ENV=development
LOG_LEVEL=info
# WORKSPACE_ROOT=./  # Defaults to project root if not set

# Tool Configuration
ENABLE_UNSAFE_TOOLS=false
ALLOWED_FILE_EXTENSIONS=.js,.mjs,.json,.md,.txt

# API Keys
# NOTE: All secrets below can also be managed via the Secrets Vault UI (Cmd+K → "Secrets Vault").
# Secrets stored in the vault (.secrets.enc) are AES-256-GCM encrypted at rest.
# Priority: Shell env vars > Vault secrets > .env file > defaults
OPENAI_API_KEY=your_openai_key_here
ANTHROPIC_API_KEY=your_anthropic_key_here
GOOGLE_API_KEY=your_google_api_key_here

# External Service Keys
# ELEVENLABS_API_KEY=            # Text-to-speech via ElevenLabs
# SERPER_API_KEY=                # Web search via Serper.dev

# Symbolic Continuity
# SYMBOLIC_CONTINUITY=true                    # Enable/disable symbolic continuity (default: true)
# SYMBOLIC_CONTINUITY_CHINESE_ROOM=false      # Enable Chinese Room Mode — encrypted private symbolic space (default: false)
# SYMBOLIC_CONTINUITY_SECRET=                 # Optional encryption secret. Auto-generated if empty.

# OpenClaw Integration
# OPENCLAW_MODE=external        # 'integrated' or 'external'
# OPENCLAW_URL=ws://127.0.0.1:18789
# OPENCLAW_AUTH_TOKEN=
# OPENCLAW_PATH=/path/to/openclaw

# WebLLM — In-Browser AI (optional, no API keys needed)
# Runs AI models directly in your browser using WebGPU. No data leaves your machine.
# Requires a WebGPU-capable browser (Chrome 113+, Edge 113+).
# Set AI_PROVIDER=webllm and open the Oboto UI to load a model.
# Recommended model: Qwen2.5-Coder-7B-Instruct-q4f16_1-MLC (~5GB VRAM)
# Lighter alternative: Llama-3.2-3B-Instruct-q4f16_1-MLC (~3GB VRAM)
# AI_PROVIDER=webllm
# AI_MODEL=Qwen2.5-Coder-7B-Instruct-q4f16_1-MLC

# Oboto Cloud (optional)
# Sign up at https://oboto.ai to get your cloud credentials.
# Leave blank to run Oboto in standalone mode (no cloud features).
# OBOTO_CLOUD_URL=https://your-project.supabase.co
# OBOTO_CLOUD_KEY=your-anon-key
# OBOTO_CLOUD_AUTO_LOGIN=true           # Auto-login from cached token on startup (default: true)
# OBOTO_CLOUD_SYNC_INTERVAL=30000       # Workspace sync interval in ms (default: 30s)
# OBOTO_CLOUD_PRESENCE_INTERVAL=60000   # Presence heartbeat interval in ms (default: 60s)
